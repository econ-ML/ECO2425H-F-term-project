{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ba2e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: linearmodels in /opt/conda/lib/python3.11/site-packages (6.1)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.13.0 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (1.0.0)\n",
      "Requirement already satisfied: Cython>=3.0.10 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (3.0.11)\n",
      "Requirement already satisfied: pyhdfe>=0.1 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (0.2.0)\n",
      "Requirement already satisfied: formulaic>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from linearmodels) (1.0.2)\n",
      "Requirement already satisfied: setuptools-scm<9.0.0,>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (8.1.0)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from formulaic>=1.0.0->linearmodels) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from formulaic>=1.0.0->linearmodels) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in /opt/conda/lib/python3.11/site-packages (from formulaic>=1.0.0->linearmodels) (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4.0->linearmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4.0->linearmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4.0->linearmodels) (2023.3)\n",
      "Requirement already satisfied: packaging>=20 in /opt/conda/lib/python3.11/site-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (23.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (68.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.11/site-packages (from statsmodels>=0.13.0->linearmodels) (0.5.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels>=0.13.0->linearmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt  \n",
    "import sklearn.model_selection as skm                      \n",
    "!pip install linearmodels\n",
    "from linearmodels.panel import PanelOLS\n",
    "from statsmodels.api import OLS, add_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0514435f",
   "metadata": {},
   "source": [
    "Information from Bruhn et al \"The Impact of High School Financial Education: Evidence from a Large-Scale Evaluation in Brazil\" Read_me.txt file:\n",
    "- school_admin_data_final.dta contains grade level passing, failing, and dropout rates from administrative school data \n",
    "- school_intervention_panel_final.dta contains underlying variables used in the analysis, as well as dummy variables generated based on the underlying data. \n",
    "    - Variables with \"_bl\" at the end are from the baseline survey. \n",
    "    - Variables with \"_fu\" at the end are from the follow-up survey.\n",
    "    - The data is stacked for the first and second follow-up surveys, with variable round==0 denoting the first follow-up and round==1 the second follow-up.\n",
    "    - Variables with a \"p\" after the number in the variables name, e.g. \"rp_09p_bl\" come from the parent questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16db46d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_175/4246522230.py:2: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata('school_intervention_panel_final.dta', convert_categoricals=False)\n"
     ]
    }
   ],
   "source": [
    "#load the datasets into a pandas DataFrame\n",
    "df = pd.read_stata('school_intervention_panel_final.dta', convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566d7c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_geral', 'cd_escola', 'nm_uf_bl', 'matriculas', 'docentes', 'abandonona1sriemdio', 'aprovaona1sriemdio', 'treatment', 'pair_all', 'treatment_workshop', 'strata', 'round', 'female_coded', 'rp_01_bl', 'rp_08_bl', 'rp_09_bl', 'rp_14_bl', 'rp_23_bl', 'rp_24_bl', 'Student: Finanical Proficieny Score (Baseline)', 'bl_test', 'rp_49_bl', 'rp_50_bl', 'rp_53_bl', 'rp_55_bl', 'rp_56_bl', 'rp_57_bl', 'rp_59_bl', 'rp_61_bl', 'rp_64_bl', 'rp_65_bl', 'rp_88_bl', 'rp_89_bl', 'rp_90_bl', 'rp_91_bl', 'rp_92_bl', 'rp_93_bl', 'rp_94_bl', 'rp_95_bl', 'rp_96_bl', 'bl_aluno', 'rp_08p_bl', 'rp_09p_bl', 'rp_14p_bl', 'rp_18p_bl', 'rp_19p_bl', 'rp_21p_bl', 'rp_23p_bl', 'rp_33p_bl', 'rp_34p_bl', 'rp_36p_bl', 'rp_37p_bl', 'vl_proficiencia_fup', 'fu1_test', 'rp_55_fup', 'rp_57_fup', 'rp_49_fup', 'rp_50_fup', 'rp_53_fup', 'rp_56_fup', 'rp_59_fup', 'rp_61_fup', 'rp_64_fup', 'rp_65_fup', 'rp_88_fup', 'rp_89_fup', 'rp_90_fup', 'rp_91_fup', 'rp_92_fup', 'rp_93_fup', 'rp_94_fup', 'rp_95_fup', 'rp_96_fup', 'fu1_aluno', 'rp_09p_fup', 'rp_14p_fup', 'rp_18p_fup', 'rp_19p_fup', 'rp_21p_fup', 'rp_23p_fup', 'rp_33p_fup', 'rp_34p_fup', 'rp_36p_fup', 'rp_37p_fup', 'fu1_responsavel', 'fu2_test', 'rp_20_fup', 'dumm_rp_20C_fup', 'rp_55_fup2', 'fu2_aluno', 'rp_12p_fup', 'dumm_rp_12Cp_fup', 'rp_08p_fup', 'rp_13p_fup', 'rp_41p_fup', 'fu2_responsavel', 'autonomia_final2_fup', 'poupar_final2_fup', 'autonomia_final2_bl', 'poupar_final2_bl', 'Student gender could not be coded based on name (Baseline)', 'Student is female (Baseline)', 'Education of mother: At least some secondary (Baseline)', 'Education of father: At least some secondary (Baseline)', \"Student's Family receives Bolsa Familia cash transfer (Baseline)\", 'Student has computer with internet at home (Baseline)', 'Student has failed at least one school year (Baseline)', 'Student is not working at the moment (Baseline)', 'Student works in own or family business (Baseline)', 'Student works as employee or other (Baseline)', 'Student receives income (Baseline)', 'Student part of income saved is non-zero (Baseline)', 'Student has borrowed money (any source) (Baseline)', 'Student is behind on payments (unconditional) (Baseline)', 'Student is behind on payments to bank or FI (Baseline)', 'Student is behind on payments to store (Baseline)', 'Student is behind on payments to family friends or other people (Baseline)', 'Student says they are a saver (Baseline)', 'Student has formal savings (Baseline)', 'Student makes a list of all monthly expenses (Baseline)', 'Student saves money for future purchases (Baseline)', 'dumm_rp_88C_bl', 'dumm_rp_88D_bl', 'dumm_rp_88AB_bl', 'dumm_rp_89C_bl', 'dumm_rp_89D_bl', 'dumm_rp_89AB_bl', 'dumm_rp_90C_bl', 'dumm_rp_90D_bl', 'dumm_rp_90AB_bl', 'dumm_rp_91C_bl', 'dumm_rp_91D_bl', 'dumm_rp_91AB_bl', 'dumm_rp_92C_bl', 'dumm_rp_92D_bl', 'dumm_rp_92AB_bl', 'Student has bought electronics shoes or clothing with credit card (Baseline)', 'Student has bought electronics shoes or clothing on installments (Baseline)', 'Student has bought electronics shoes or clothing with cash/debit card (Baseline)', 'dumm_rp_93_bl', 'dumm_rp_94_bl', 'dumm_rp_95_bl', 'dumm_rp_96_bl', 'Student negotiates prices or payment methods (Baseline)', 'Student comparison shops before making purchase (Baseline)', 'Parent has at least some secondary education (Baseline)', 'Parent is an employee (Baseline)', 'Parent is self-employeed (Baseline)', 'Parent occupation is other (homemaker, retired, unemployed, other) (Baseline)', 'Parent: makes a list of all monthly expenses (Baseline)', 'Parent: has savings account (Baseline)', 'Parent: has debit card (Baseline)', 'dumm_rp_21p_bl', 'Parent: has checks (Baseline)', ' Parent: has formal savings (Baseline)', 'Parent: Student talks to you about finances (Baseline)', 'Parent: Student helps organize HH budget (Baseline)', 'Parent: Prefers R50K plus 15 percent interest (Baseline)', 'Parent: Inflation question dummy for correct (Baseline)', 'Student is not working at the moment', 'Student works in own or family busines', 'Student works as employee or other', 'Student: Receives income', 'Student: Pct of income saved is non-zero', 'Student: Has borrowed money (any source)', 'Student: Is behind on payments (unconditional)', 'Student: Is behind on payments to bank or FI', 'Student: Is behind on payments to store', 'Student: Is behind on payments to family friends or other people', 'Student: Says they are a saver', 'Student: Has formal savings', 'I make a list of all monthly expenses', 'Student: Saves money for future purchases', 'Student: I have bought cell phone with credit card', 'Student: I have bought cell phone on installments', 'Student: I have bought a cell phone with cash/debit card', 'Student: I have bought computer with credit card', 'Student: I have bought computer on installments', 'Student: I have bought a computer with cash/debit card', 'Student: I have bought an electronic device with credit card', 'Student: I have bought an electronic device on installments', 'Student: I have bought an electronic device with cash/debit card', 'Student: I have bought shoes with credit card', 'Student: I have bought shoes on installments', 'Student: I have bought shoes with cash/debit card', 'Student: I have bought clothing with credit card', 'Student: I have bought clothing on installments', 'Student: I have bought clothing with cash/debit card', 'I have bought electronics shoes or clothing with credit card', 'I have bought electronics shoes or clothing on installments', 'I have bought electronics shoes or clothing with cash/debit card', 'I negotiate the price', 'Student I search price in different stores', 'Student I negotiate the payment method', 'Student: I search similar models/brands', 'Student Negotiates prices or payment methods', 'Student Comparison shops before making purchase', 'Parent has at least some secondary education', 'Parent is an employee', 'Student Parent is self-employeed', \"Student Parent's occupation is other (homemaker, retired, unemployed, other)\", 'Parent: makes a list of all monthly expenses', 'Parent: has checking account', 'Parent: savings account', 'Parent has debit card', 'Parent has checks', 'Parent has formal savings', 'Parent: Student talks to you about finances', 'Parent: student helps organize HH budget', 'Parent: prefers R50K plus 15 percent interest (follow up)', 'Parent: Inflation question dummy for correct  (follow up)', 'Parent: budget must have income and expenses (follow up)']\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={\n",
    "    'female' : 'Student is female (Baseline)',\n",
    "    'miss_f_coded' : 'Student gender could not be coded based on name (Baseline)',\n",
    "    'dumm_rp_08_bl' : 'Education of mother: At least some secondary (Baseline)',\n",
    "    'dumm_rp_09_bl' : 'Education of father: At least some secondary (Baseline)',\n",
    "    'dumm_rp_14_bl' : 'Student\\'s Family receives Bolsa Familia cash transfer (Baseline)',\n",
    "    'dumm_rp_23_bl' : 'Student has computer with internet at home (Baseline)',\n",
    "    'dumm_rp_24_bl' : 'Student has failed at least one school year (Baseline)',\n",
    "    'dumm_rp_49_bl' : 'Student is not working at the moment (Baseline)',\n",
    "    'business_bl' : 'Student works in own or family business (Baseline)',\n",
    "    'employee_bl' : 'Student works as employee or other (Baseline)',\n",
    "    'dumm_rp_50_bl' : 'Student receives income (Baseline)',\n",
    "    'dumm_rp_53B_bl' : 'Student part of income saved is non-zero (Baseline)',\n",
    "    'dumm_rp_55_bl' : 'Student has borrowed money (any source) (Baseline)',\n",
    "    'dumm_rp_56_bl' : 'Student is behind on payments (unconditional) (Baseline)',\n",
    "    'dumm_rp_57s_bl' : 'Student is behind on payments to store (Baseline)',\n",
    "    'dumm_rp_57i_bl' : 'Student is behind on payments to family friends or other people (Baseline)',\n",
    "    'dumm_rp_57f_bl' : 'Student is behind on payments to bank or FI (Baseline)',\n",
    "    'dumm_rp_59_bl' : 'Student says they are a saver (Baseline)',\n",
    "    'dumm_rp_61_bl' : 'Student has formal savings (Baseline)',\n",
    "    'dumm_rp_64A_bl' : 'Student makes a list of all monthly expenses (Baseline)',\n",
    "    'dumm_rp_65A_bl': 'Student saves money for future purchases (Baseline)',\n",
    "    'dumm_rp88__92C_bl': 'Student has bought electronics shoes or clothing with credit card (Baseline)',\n",
    "    'dumm_rp88__92D_bl': 'Student has bought electronics shoes or clothing on installments (Baseline)',\n",
    "    'dumm_rp88__92AB_bl': 'Student has bought electronics shoes or clothing with cash/debit card (Baseline)',\n",
    "    'dumm_negotiates_bl': 'Student negotiates prices or payment methods (Baseline)',\n",
    "    'dumm_search_bl': 'Student comparison shops before making purchase (Baseline)',\n",
    "    'dumm_rp_08p_bl': 'Parent has at least some secondary education (Baseline)',\n",
    "    'p_employee_bl': 'Parent is an employee (Baseline)',\n",
    "    'p_selfempl_bl': 'Parent is self-employeed (Baseline)',\n",
    "    'p_other_bl': 'Parent occupation is other (homemaker, retired, unemployed, other) (Baseline)',\n",
    "    'dumm_rp_14p_bl': 'Parent: makes a list of all monthly expenses (Baseline)',\n",
    "    'dumm_rp_18p_bl': 'Parent: has checking account (Baseline)',\n",
    "    'dumm_rp_18p_bl': 'Parent: has savings account (Baseline)',\n",
    "    'dumm_rp_19p_bl': 'Parent: has debit card (Baseline)',\n",
    "    'dumm_rp_23p_bl': 'Parent: has checks (Baseline)',\n",
    "    'dumm_formal_saving_bl':' Parent: has formal savings (Baseline)',\n",
    "    'dumm_rp_33p_bl': 'Parent: Student talks to you about finances (Baseline)',\n",
    "    'dumm_rp_34p_bl': 'Parent: Student helps organize HH budget (Baseline)',\n",
    "    'dumm_rp_36p_bl': 'Parent: Prefers R50K plus 15 percent interest (Baseline)',\n",
    "    'dumm_rp_37p_bl': 'Parent: Inflation question dummy for correct (Baseline)',\n",
    "    'vl_proficiencia_bl': 'Student: Finanical Proficieny Score (Baseline)', \n",
    "    'dumm_rp_49_fup' : \"Student is not working at the moment\" ,  \n",
    "    'business_fup' : 'Student works in own or family busines' ,\n",
    "    'employee_fup' : 'Student works as employee or other', \n",
    "    'dumm_rp_50_fup': 'Student: Receives income' ,\n",
    "     'dumm_rp_53B_fup': 'Student: Pct of income saved is non-zero', \n",
    "    'dumm_rp_55_fup': 'Student: Has borrowed money (any source)',\n",
    "    'dumm_rp_56_fup' : 'Student: Is behind on payments (unconditional)',\n",
    "    'dumm_rp_57f_fup' : 'Student: Is behind on payments to bank or FI' ,\n",
    "    'dumm_rp_57s_fup' : 'Student: Is behind on payments to store',\n",
    "    'dumm_rp_57i_fup': 'Student: Is behind on payments to family friends or other people', \n",
    "    'dumm_rp_59_fup' : 'Student: Says they are a saver' , \n",
    "    'dumm_rp_61_fup' : 'Student: Has formal savings', \n",
    "    'dumm_rp_64A_fup' : 'I make a list of all monthly expenses', \n",
    "    'dumm_rp_65A_fup' : 'Student: Saves money for future purchases',\n",
    "    'dumm_rp_88C_fup': 'Student: I have bought cell phone with credit card', \n",
    "    'dumm_rp_88D_fup': 'Student: I have bought cell phone on installments',\n",
    "    'dumm_rp_88AB_fup': 'Student: I have bought a cell phone with cash/debit card',\n",
    "    'dumm_rp_89C_fup': 'Student: I have bought computer with credit card' ,\n",
    "    'dumm_rp_89D_fup': 'Student: I have bought computer on installments' ,\n",
    "    'dumm_rp_89AB_fup': 'Student: I have bought a computer with cash/debit card' ,\n",
    "    'dumm_rp_90C_fup': 'Student: I have bought an electronic device with credit card' ,\n",
    "    'dumm_rp_90D_fup': 'Student: I have bought an electronic device on installments' ,\n",
    "    'dumm_rp_90AB_fup': 'Student: I have bought an electronic device with cash/debit card' ,\n",
    "    'dumm_rp_91C_fup': 'Student: I have bought shoes with credit card' ,\n",
    "    'dumm_rp_91D_fup': 'Student: I have bought shoes on installments' ,\n",
    "    'dumm_rp_91AB_fup': 'Student: I have bought shoes with cash/debit card',\n",
    "    'dumm_rp_92C_fup': 'Student: I have bought clothing with credit card', \n",
    "    'dumm_rp_92D_fup': 'Student: I have bought clothing on installments' ,\n",
    "    'dumm_rp_92AB_fup' : 'Student: I have bought clothing with cash/debit card',\n",
    "    'dumm_rp88__92C_fup': 'I have bought electronics shoes or clothing with credit card',\n",
    "    'dumm_rp88__92D_fup': 'I have bought electronics shoes or clothing on installments' ,\n",
    "    'dumm_rp88__92AB_fup': 'I have bought electronics shoes or clothing with cash/debit card' ,\n",
    "    'dumm_rp_93_fup': 'I negotiate the price' ,\n",
    "    'dumm_rp_94_fup': 'Student I search price in different stores',\n",
    "    'dumm_rp_95_fup': 'Student I negotiate the payment method' ,\n",
    "    'dumm_rp_96_fup': 'Student: I search similar models/brands' ,\n",
    "    'dumm_negotiates_fup': 'Student Negotiates prices or payment methods' ,\n",
    "    'dumm_search_fup': 'Student Comparison shops before making purchase' ,\n",
    "    'dumm_rp_08p_fup': 'Parent has at least some secondary education' ,\n",
    "    'p_employee_fup': 'Parent is an employee' ,\n",
    "    'p_selfempl_fup': 'Student Parent is self-employeed',\n",
    "    'p_other_fup': 'Student Parent\\'s occupation is other (homemaker, retired, unemployed, other)',\n",
    "    'dumm_rp_14p_fup': 'Parent: makes a list of all monthly expenses',\n",
    "    'dumm_rp_18p_fup' : 'Parent: has checking account', \n",
    "    'dumm_rp_19p_fup': 'Parent: savings account', \n",
    "    'dumm_rp_21p_fup': 'Parent has debit card' ,\n",
    "    'dumm_rp_23p_fup': 'Parent has checks' ,\n",
    "    'dumm_formal_saving_fup': 'Parent has formal savings',\n",
    "    'dumm_rp_33p_fup': 'Parent: Student talks to you about finances' ,\n",
    "    'dumm_rp_34p_fup': 'Parent: student helps organize HH budget',\n",
    "    'dumm_rp_36p_fup' : 'Parent: prefers R50K plus 15 percent interest (follow up)',\n",
    "    'dumm_rp_37p_fup' : 'Parent: Inflation question dummy for correct  (follow up)', \n",
    "    'dumm_rp_41p_fup' : 'Parent: budget must have income and expenses (follow up)',\n",
    "\n",
    "})\n",
    "column_names = df.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351cdbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful subdata sets \n",
    "follow_up_1_df = df[df['round'] == 0]\n",
    "follow_up_2_df = df[df['round'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7557755",
   "metadata": {},
   "source": [
    "## Replication of Paper OLS Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f0fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133/3020795279.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cd_escola'] = data['cd_escola'].astype('category')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m subset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([subset, pair_dummies], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(pd\u001b[38;5;241m.\u001b[39mconcat([subset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m], pair_dummies], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 55\u001b[0m y \u001b[38;5;241m=\u001b[39m subset[\u001b[43mvar\u001b[49m]\n\u001b[1;32m     56\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mastype({col: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns})\n\u001b[1;32m     57\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'var' is not defined"
     ]
    }
   ],
   "source": [
    "# Replication of Paper OLS Regression Results \n",
    "data = df\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "\n",
    "# Helper function for summarizing control group stats\n",
    "def summarize_control_group(df, var, treatment_col='treatment'):\n",
    "    control_group = df[(df[treatment_col] == 0) & df['e_sample']]\n",
    "    mean = control_group[var].mean()\n",
    "    std = control_group[var].std()\n",
    "    return mean, std\n",
    "\n",
    "# Create e_sample column for the subset used in the model\n",
    "data['e_sample'] = (~df[outcome].isnull()) & df['treatment'].notnull()\n",
    "\n",
    "# Results container for Panel A, B, and C\n",
    "results = []\n",
    "\n",
    "# Run Panel A and Panel B analysis for round 0 and 1\n",
    "for round_ in [0, 1]:\n",
    "    data = data.dropna(subset=['treatment', outcome, 'round', 'cd_escola'])\n",
    "    data['cd_escola'] = data['cd_escola'].astype('category')\n",
    "    subset = data[data['round'] == round_]\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    \n",
    "    # Panel A regression (no controls, clustered standard errors)\n",
    "    model_a = smf.ols(f'Q(\"{outcome}\") ~ treatment', data=subset).fit(cov_type='cluster', \n",
    "                                                                  cov_kwds={'groups': subset['cd_escola']})\n",
    "    control_mean_a, control_sd_a = summarize_control_group(subset, outcome)\n",
    "    f_test_a = model_a.f_test(\"treatment = 0\").pvalue\n",
    "    \n",
    "    results.append({\n",
    "        'panel': 'A',\n",
    "        'round': round_,\n",
    "        'coeff_treatment': model_a.params['treatment'],\n",
    "        'se_treatment': model_a.bse['treatment'],\n",
    "        'control_mean': control_mean_a,\n",
    "        'control_sd': control_sd_a,\n",
    "        'f_test': f_test_a,\n",
    "        'r2': model_a.rsquared,\n",
    "        'N': model_a.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "    \n",
    "    # Panel B regression (cluster standard error, school pair dummies control)\n",
    "\n",
    "    subset[f'flag_{outcome}{round_}'] = subset.groupby('pair_all')['treatment'].transform('mean')\n",
    "    subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "    subset.loc[(subset[f'flag_{outcome}{round_}'] == 0) | (subset[f'flag_{outcome}{round_}'] == 1), f'pair_{outcome}{round_}'] = 0\n",
    "    subset = subset.dropna(subset='pair_all')\n",
    "    \n",
    "    pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "    subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "    \n",
    "    X = sm.add_constant(pd.concat([subset['treatment'], pair_dummies], axis=1))\n",
    "    y = subset[var]\n",
    "    X = X.astype({col: 'int' for col in X.select_dtypes(include=['bool']).columns})\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    model_b = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "    control_group = subset[subset['treatment'] == 0]\n",
    "    control_mean = control_group[var].mean()\n",
    "    control_sd = control_group[var].std()\n",
    "\n",
    "    # Collect results\n",
    "    results.append({\n",
    "        'panel': 'B',\n",
    "        'round': round_,\n",
    "        'outcome': var,\n",
    "        'coeff_treatment': model_b.params['treatment'],\n",
    "        'se_treatment': model_b.bse['treatment'],\n",
    "        'control_mean': control_mean,\n",
    "        'control_sd': control_sd,\n",
    "        'f_test_p_value': None,  # Add this if you perform F-tests later\n",
    "        'r2': model_b.rsquared,\n",
    "        'N': model_b.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "    \n",
    "    #Pannel C (With school pair dummies, baseline dependent variable, and student gender controls) \n",
    "    bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "    subset[f'miss_{bl}'] = 0\n",
    "    subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "    subset[bl].fillna(0, inplace=True)\n",
    "    \n",
    "    subset['miss_f_coded'] = 0\n",
    "    subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "    subset['female_coded'].fillna(0, inplace=True)\n",
    "    \n",
    "    subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "    pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "    subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "    \n",
    "    pair_dummies = pair_dummies.astype('int')\n",
    "    X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded']], pair_dummies], axis=1))\n",
    "    y = subset[outcome]\n",
    "    \n",
    "    model_c = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "    \n",
    "    control_group = subset[subset['treatment'] == 0]\n",
    "    control_mean = control_group[outcome].mean()\n",
    "    control_sd = control_group[outcome].std()\n",
    "    \n",
    "    results.append({\n",
    "        'panel': 'C',\n",
    "        'round': round_,\n",
    "        'outcome': outcome,\n",
    "        'coeff_treatment': model_c.params['treatment'],\n",
    "        'se_treatment': model_c.bse['treatment'],\n",
    "        'control_mean': control_mean,\n",
    "        'control_sd': control_sd,\n",
    "        'f_test_p_value': None,  \n",
    "        'r2': model_c.rsquared,\n",
    "        'N': model_c.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "    \n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e31a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133/1023768971.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cd_escola'] = data['cd_escola'].astype('category')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel': 'A', 'round': 0, 'coeff_treatment': -0.006154123533212073, 'se_treatment': 0.00945055430604901, 'p_value_treatment': 0.5149226786374965, 'control_mean': 0.2516129, 'control_sd': 0.43397289514541626, 'f_test': 0.5150999333939976, 'r2': 5.05843004297013e-05, 'N': 16338.0, 'N_clust': 845}\n",
      "{'panel': 'B', 'round': 0, 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.007933187804941042, 'se_treatment': 0.006119280628448203, 'p_value_treatment': 0.19482913650840594, 'control_mean': 0.2516129, 'control_sd': 0.43397289514541626, 'f_test_p_value': None, 'r2': 0.056098408042394854, 'N': 16338.0, 'N_clust': 845}\n",
      "{'panel': 'C', 'round': 0, 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0008663793504490409, 'se_treatment': 0.005292955456165285, 'p_value_treatment': 0.8699788384910333, 'control_mean': 0.2516129, 'control_sd': 0.43397289514541626, 'f_test_p_value': None, 'r2': 0.23428691746172248, 'N': 16338.0, 'N_clust': 845}\n",
      "{'panel': 'A', 'round': 1, 'coeff_treatment': 0.016082225203884845, 'se_treatment': 0.009710206985759886, 'p_value_treatment': 0.09767756235111123, 'control_mean': 0.2795575, 'control_sd': 0.4487948417663574, 'f_test': 0.09804926111790938, 'r2': 0.0003153053563799135, 'N': 17760.0, 'N_clust': 845}\n",
      "{'panel': 'B', 'round': 1, 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.012312263874978253, 'se_treatment': 0.006082351337281815, 'p_value_treatment': 0.0429433502129497, 'control_mean': 0.2795575, 'control_sd': 0.4487948417663574, 'f_test_p_value': None, 'r2': 0.05670107791227941, 'N': 17760.0, 'N_clust': 845}\n",
      "{'panel': 'C', 'round': 1, 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.016344071720206008, 'se_treatment': 0.005819971584261374, 'p_value_treatment': 0.004980791263992034, 'control_mean': 0.2795575, 'control_sd': 0.4487948417663574, 'f_test_p_value': None, 'r2': 0.12818820149940713, 'N': 17760.0, 'N_clust': 845}\n"
     ]
    }
   ],
   "source": [
    "# Replication of Paper OLS Regression Results \n",
    "data = df\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "\n",
    "# Helper function for summarizing control group stats\n",
    "def summarize_control_group(df, var, treatment_col='treatment'):\n",
    "    control_group = df[(df[treatment_col] == 0) & df['e_sample']]\n",
    "    mean = control_group[var].mean()\n",
    "    std = control_group[var].std()\n",
    "    return mean, std\n",
    "\n",
    "# Create e_sample column for the subset used in the model\n",
    "data['e_sample'] = (~df[outcome].isnull()) & df['treatment'].notnull()\n",
    "\n",
    "# Results container for Panel A, B, and C\n",
    "results = []\n",
    "\n",
    "# Run Panel A and Panel B analysis for round 0 and 1\n",
    "for round_ in [0, 1]:\n",
    "    data = data.dropna(subset=['treatment', outcome, 'round', 'cd_escola'])\n",
    "    data['cd_escola'] = data['cd_escola'].astype('category')\n",
    "    subset = data[data['round'] == round_]\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    \n",
    "    # Panel A regression (no controls, clustered standard errors)\n",
    "    model_a = smf.ols(f'Q(\"{outcome}\") ~ treatment', data=subset).fit(cov_type='cluster', \n",
    "                                                                      cov_kwds={'groups': subset['cd_escola']})\n",
    "    control_mean_a, control_sd_a = summarize_control_group(subset, outcome)\n",
    "    f_test_a = model_a.f_test(\"treatment = 0\").pvalue\n",
    "    \n",
    "    results.append({\n",
    "        'panel': 'A',\n",
    "        'round': round_,\n",
    "        'coeff_treatment': model_a.params['treatment'],\n",
    "        'se_treatment': model_a.bse['treatment'],\n",
    "        'p_value_treatment': model_a.pvalues['treatment'],  # Add p-value for treatment coefficient\n",
    "        'control_mean': control_mean_a,\n",
    "        'control_sd': control_sd_a,\n",
    "        'f_test': f_test_a,\n",
    "        'r2': model_a.rsquared,\n",
    "        'N': model_a.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "    \n",
    "    # Panel B regression (cluster standard error, school pair dummies control)\n",
    "    subset[f'flag_{outcome}{round_}'] = subset.groupby('pair_all')['treatment'].transform('mean')\n",
    "    subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "    subset.loc[(subset[f'flag_{outcome}{round_}'] == 0) | (subset[f'flag_{outcome}{round_}'] == 1), f'pair_{outcome}{round_}'] = 0\n",
    "    subset = subset.dropna(subset='pair_all')\n",
    "    \n",
    "    pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "    subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "    \n",
    "    X = sm.add_constant(pd.concat([subset['treatment'], pair_dummies], axis=1))\n",
    "    y = subset[outcome]\n",
    "    X = X.astype({col: 'int' for col in X.select_dtypes(include=['bool']).columns})\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    model_b = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "    control_group = subset[subset['treatment'] == 0]\n",
    "    control_mean = control_group[outcome].mean()\n",
    "    control_sd = control_group[outcome].std()\n",
    "\n",
    "    # Collect results\n",
    "    results.append({\n",
    "        'panel': 'B',\n",
    "        'round': round_,\n",
    "        'outcome': outcome,\n",
    "        'coeff_treatment': model_b.params['treatment'],\n",
    "        'se_treatment': model_b.bse['treatment'],\n",
    "        'p_value_treatment': model_b.pvalues['treatment'],  # Add p-value for treatment coefficient\n",
    "        'control_mean': control_mean,\n",
    "        'control_sd': control_sd,\n",
    "        'f_test_p_value': None,  # Add this if you perform F-tests later\n",
    "        'r2': model_b.rsquared,\n",
    "        'N': model_b.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "    \n",
    "    # Panel C regression (With school pair dummies, baseline dependent variable, and student gender controls) \n",
    "    bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "    subset[f'miss_{bl}'] = 0\n",
    "    subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "    subset[bl].fillna(0, inplace=True)\n",
    "    \n",
    "    subset['miss_f_coded'] = 0\n",
    "    subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "    subset['female_coded'].fillna(0, inplace=True)\n",
    "    \n",
    "    subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "    pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "    subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "    \n",
    "    pair_dummies = pair_dummies.astype('int')\n",
    "    X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded']], pair_dummies], axis=1))\n",
    "    y = subset[outcome]\n",
    "    \n",
    "    model_c = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "    \n",
    "    control_group = subset[subset['treatment'] == 0]\n",
    "    control_mean = control_group[outcome].mean()\n",
    "    control_sd = control_group[outcome].std()\n",
    "    \n",
    "    results.append({\n",
    "        'panel': 'C',\n",
    "        'round': round_,\n",
    "        'outcome': outcome,\n",
    "        'coeff_treatment': model_c.params['treatment'],\n",
    "        'se_treatment': model_c.bse['treatment'],\n",
    "        'p_value_treatment': model_c.pvalues['treatment'],  # Add p-value for treatment coefficient\n",
    "        'control_mean': control_mean,\n",
    "        'control_sd': control_sd,\n",
    "        'f_test_p_value': None,  \n",
    "        'r2': model_c.rsquared,\n",
    "        'N': model_c.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb71eb64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stargazer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Output not used in report, ended up manually creating the table in Latex \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstargazer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstargazer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stargazer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming you have model_a, model_b, and model_c defined\u001b[39;00m\n\u001b[1;32m      5\u001b[0m stargazer \u001b[38;5;241m=\u001b[39m Stargazer([model_a, model_b, model_c])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stargazer'"
     ]
    }
   ],
   "source": [
    "#Output not used in report, ended up manually creating the table in Latex \n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "# Assuming you have model_a, model_b, and model_c defined\n",
    "stargazer = Stargazer([model_a, model_b, model_c])\n",
    "\n",
    "# Customize the table\n",
    "stargazer.title(\"OLS Regression Results for Student Purchasing Behavior\")\n",
    "stargazer.custom_columns(['Panel A: No controls', 'Panel B: With school pair dummies', \n",
    "                          'Panel C: With school pair dummies, baseline dependent variable, and student gender'], [1, 1, 1])\n",
    "stargazer.show_r2 = True\n",
    "stargazer.show_n = True\n",
    "stargazer.covariate_order(['treatment'])\n",
    "\n",
    "# Render to LaTeX\n",
    "latex_table = stargazer.render_latex()\n",
    "\n",
    "# Add custom footer\n",
    "footer = r\"\"\"\n",
    "\\midrule\n",
    "\\multicolumn{8}{l}{Sample size (number of students)} & 16,667 & 18,033 \\\\\n",
    "\\multicolumn{8}{l}{Number of schools} & 845 & 845 \\\\\n",
    "\\multicolumn{8}{l}{Dependent variable mean in control group} & 0.825 & 0.834 \\\\\n",
    "\\multicolumn{8}{l}{$F$-test $p$-value (treatment on background characteristics)} & 0.283 & 0.232 \\\\\n",
    "\"\"\"\n",
    "\n",
    "# Combine the table and footer\n",
    "full_table = latex_table.replace(r'\\bottomrule', footer + r'\\bottomrule')\n",
    "\n",
    "# Print or save the LaTeX table\n",
    "#print(full_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ffeb3",
   "metadata": {},
   "source": [
    "## Saver Interaction Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41bdd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel': 'D', 'round': 0, 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.017576772070336696, 'coeff_interaction': 0.026554737160763165, 'se_treatment': 0.01160776127985561, 'se_interaction': 0.014241645210263866, 'control_mean': 0.2491794, 'control_sd': 0.4325709044933319, 'f_test_p_value': None, 'r2': 0.008424180894333944, 'N': 14749.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0006785541548850649, 'coeff_interaction': 0.013682871082945677, 'se_treatment': 0.013406061461388785, 'se_interaction': 0.017844898749732826, 'control_mean': 0.2757798, 'control_sd': 0.44694268703460693, 'f_test_p_value': None, 'r2': 0.007134713777116608, 'N': 10942.0, 'N_clust': 796}\n"
     ]
    }
   ],
   "source": [
    "#'dumm_rp_59_bl' : 'Student says they are a saver (Baseline)'\n",
    "# Define the new interaction variable\n",
    "interaction_var = 'Student says they are a saver (Baseline)'\n",
    "data['interaction_term'] = data['treatment'] * data[interaction_var]\n",
    "\n",
    "interaction_results = []\n",
    "# Create Panel D for interaction analysis\n",
    "for round_ in [0, 1]:\n",
    "    subset = data[data['round'] == round_].dropna(subset=['treatment', outcome, interaction_var, 'cd_escola'])\n",
    "    subset = subset.reset_index(drop=True)\n",
    "    subset['cd_escola'] = subset['cd_escola'].astype('category')\n",
    "\n",
    "    # Add interaction term\n",
    "    subset['interaction_term'] = subset['treatment'] * subset[interaction_var]\n",
    "\n",
    "    # Panel D regression (with interaction term, clustered standard errors)\n",
    "    X = sm.add_constant(subset[['treatment', interaction_var, 'interaction_term']])\n",
    "    y = subset[outcome]\n",
    "\n",
    "    model_d = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "    # Calculate control group statistics for this panel\n",
    "    control_group = subset[subset['treatment'] == 0]\n",
    "    control_mean = control_group[outcome].mean()\n",
    "    control_sd = control_group[outcome].std()\n",
    "\n",
    "    # Collect results for Panel D\n",
    "    interaction_results.append({\n",
    "        'panel': 'D',\n",
    "        'round': round_,\n",
    "        'outcome': outcome,\n",
    "        'coeff_treatment': model_d.params['treatment'],\n",
    "        'coeff_interaction': model_d.params['interaction_term'],\n",
    "        'se_treatment': model_d.bse['treatment'],\n",
    "        'se_interaction': model_d.bse['interaction_term'],\n",
    "        'control_mean': control_mean,\n",
    "        'control_sd': control_sd,\n",
    "        'f_test_p_value': None,  # Update if performing F-tests later\n",
    "        'r2': model_d.rsquared,\n",
    "        'N': model_d.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "    })\n",
    "\n",
    "# Print or inspect results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"OLS Regression Results with Interaction Term\", dataframe=pd.DataFrame(results))\n",
    "for interaction_results in interaction_results:\n",
    "    print(interaction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ffd07",
   "metadata": {},
   "source": [
    "### Cluster 0 Interaction Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4579606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'interaction varialbe': 'Student works in own or family business (Baseline)', 'round': 1}, {'interaction varialbe': 'Student part of income saved is non-zero (Baseline)', 'round': 1}, {'interaction varialbe': 'Student is behind on payments to bank or FI (Baseline)', 'round': 1}, {'interaction varialbe': 'Student says they are a saver (Baseline)', 'round': 1}, {'interaction varialbe': 'Student makes a list of all monthly expenses (Baseline)', 'round': 1}, {'interaction varialbe': 'Student saves money for future purchases (Baseline)', 'round': 1}, {'interaction varialbe': 'Parent is an employee (Baseline)', 'round': 0}, {'interaction varialbe': 'Parent: makes a list of all monthly expenses (Baseline)', 'round': 0}, {'interaction varialbe': 'Parent: makes a list of all monthly expenses (Baseline)', 'round': 1}, {'interaction varialbe': 'Parent: has debit card (Baseline)', 'round': 0}, {'interaction varialbe': 'Parent: has debit card (Baseline)', 'round': 1}, {'interaction varialbe': 'Parent: has checks (Baseline)', 'round': 1}, {'interaction varialbe': 'Parent: Inflation question dummy for correct (Baseline)', 'round': 1}]\n",
      "<built-in method append of list object at 0x7f5f263004c0>\n"
     ]
    }
   ],
   "source": [
    "interaction_var_0 = ['Education of mother: At least some secondary (Baseline)',\n",
    "       'Education of father: At least some secondary (Baseline)',\n",
    "       'Student has failed at least one school year (Baseline)',\n",
    "       'Student works in own or family business (Baseline)',\n",
    "       'Student part of income saved is non-zero (Baseline)',\n",
    "       'Student is behind on payments to bank or FI (Baseline)',\n",
    "       'Student says they are a saver (Baseline)',\n",
    "       'Student has formal savings (Baseline)',\n",
    "       'Student makes a list of all monthly expenses (Baseline)',\n",
    "       'Student saves money for future purchases (Baseline)',\n",
    "       'Parent has at least some secondary education (Baseline)',\n",
    "       'Parent is an employee (Baseline)',\n",
    "       'Parent is self-employeed (Baseline)',\n",
    "       'Parent: makes a list of all monthly expenses (Baseline)',\n",
    "       'Parent: has debit card (Baseline)', 'dumm_rp_21p_bl',\n",
    "       'Parent: has checks (Baseline)',\n",
    "       'Parent: Prefers R50K plus 15 percent interest (Baseline)',\n",
    "       'Parent: Inflation question dummy for correct (Baseline)']\n",
    "positive_t = []\n",
    "negative_t = []\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "interaction_results = []\n",
    "for interaction_var in interaction_var_0:\n",
    "    data = df\n",
    "    data = df.dropna(subset=['treatment', outcome, 'round', 'cd_escola', interaction_var]).copy()\n",
    "    data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
    "    # Create Panel D for interaction analysis\n",
    "    for round_ in [0, 1]:\n",
    "        subset = data[data['round'] == round_].dropna(subset=['treatment', outcome, interaction_var, 'cd_escola'])\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        subset['cd_escola'] = subset['cd_escola'].astype('category')\n",
    "        \n",
    "        bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "        subset[f'miss_{bl}'] = 0\n",
    "        subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "        subset[bl].fillna(0, inplace=True)\n",
    "        \n",
    "        subset['miss_f_coded'] = 0\n",
    "        subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "        subset['female_coded'].fillna(0, inplace=True)\n",
    "        \n",
    "        subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "        pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "        subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "        pair_dummies = pair_dummies.astype('int')\n",
    "        \n",
    "        # Add interaction term\n",
    "        subset['interaction_term'] = subset['treatment'] * subset[interaction_var]\n",
    "\n",
    "        # Panel D regression (with interaction term, clustered standard errors\n",
    "        X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded', \n",
    "                                              interaction_var, 'interaction_term']], pair_dummies], axis=1))\n",
    "        y = subset[outcome]\n",
    "\n",
    "        model_d = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "        # Calculate control group statistics for this panel\n",
    "        control_group = subset[subset['treatment'] == 0]\n",
    "        control_mean = control_group[outcome].mean()\n",
    "        control_sd = control_group[outcome].std()\n",
    "\n",
    "        # Collect results for Panel D\n",
    "        interaction_results.append({\n",
    "            'panel': 'D',\n",
    "            'round': round_,\n",
    "            'interaction varialbe': interaction_var,\n",
    "            'outcome': outcome,\n",
    "            'coeff_treatment': model_d.params['treatment'],\n",
    "            'coeff_interaction': model_d.params['interaction_term'],\n",
    "            'se_treatment': model_d.bse['treatment'],\n",
    "            'se_interaction': model_d.bse['interaction_term'],\n",
    "            'control_mean': control_mean,\n",
    "            'control_sd': control_sd,\n",
    "            'f_test_p_value': None, \n",
    "            'r2': model_d.rsquared,\n",
    "            'N': model_d.nobs,\n",
    "            'N_clust': subset['cd_escola'].nunique() })\n",
    "        \n",
    "        if model_d.params['treatment'] > 0: \n",
    "            positive_t.append({'interaction varialbe': interaction_var, 'round': round_})\n",
    "  \n",
    "        if model_d.params['treatment'] < 0: \n",
    "            negative_t.append({'interaction varialbe': interaction_var, 'round': round_,})\n",
    "\n",
    "#Print or inspect results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"OLS Regression Results with Interaction Term\", dataframe=pd.DataFrame(results))\n",
    "#for interaction_results in interaction_results:\n",
    "    #print(interaction_results)\n",
    "\n",
    "print(positive_t)\n",
    "print(negative_t.append)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e360b6c",
   "metadata": {},
   "source": [
    "### Cluster 1 Interaction Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a09e5745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student is not working at the moment (Baseline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/845154971.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student works as employee or other (Baseline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/845154971.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student is behind on payments (unconditional) (Baseline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/845154971.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student is behind on payments to store (Baseline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/845154971.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student has bought electronics shoes or clothing on installments (Baseline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/845154971.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student is not working at the moment (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0037873351986393708, 'coeff_interaction': 0.0019564755857185982, 'se_treatment': 0.007048907449884463, 'se_interaction': 0.013824858512800447, 'control_mean': 0.24911536, 'control_sd': 0.43253278732299805, 'f_test_p_value': None, 'r2': 0.25693062220658314, 'N': 14869.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student is not working at the moment (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.006708606414392982, 'coeff_interaction': -0.011092146662088272, 'se_treatment': 0.00931346265056363, 'se_interaction': 0.017414048781635005, 'control_mean': 0.27704054, 'control_sd': 0.4475654661655426, 'f_test_p_value': None, 'r2': 0.18822524420580156, 'N': 11023.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student works as employee or other (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0042400254835131945, 'coeff_interaction': 0.005151921964779979, 'se_treatment': 0.006318431100084145, 'se_interaction': 0.01611670765527913, 'control_mean': 0.24911536, 'control_sd': 0.43253278732299805, 'f_test_p_value': None, 'r2': 0.25690203615756446, 'N': 14869.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student works as employee or other (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0027270929720232583, 'coeff_interaction': 0.0024466981248900885, 'se_treatment': 0.00848082979554593, 'se_interaction': 0.020284158981212982, 'control_mean': 0.27704054, 'control_sd': 0.4475654661655426, 'f_test_p_value': None, 'r2': 0.18799736331966377, 'N': 11023.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student is behind on payments (unconditional) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.007390178185828642, 'coeff_interaction': 0.034366379494656624, 'se_treatment': 0.0055660311719005085, 'se_interaction': 0.024822389043356867, 'control_mean': 0.24903171, 'control_sd': 0.4324817955493927, 'f_test_p_value': None, 'r2': 0.25725526445028657, 'N': 14707.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student is behind on payments (unconditional) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0016997430820677548, 'coeff_interaction': 0.028954570726841676, 'se_treatment': 0.007738866552204686, 'se_interaction': 0.03398760290748846, 'control_mean': 0.2760081, 'control_sd': 0.4470588266849518, 'f_test_p_value': None, 'r2': 0.186858322870334, 'N': 10925.0, 'N_clust': 795}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student is behind on payments to store (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.004319219926828665, 'coeff_interaction': 0.01934622851723508, 'se_treatment': 0.0054572096685922816, 'se_interaction': 0.035281683778367594, 'control_mean': 0.24889396, 'control_sd': 0.432394415140152, 'f_test_p_value': None, 'r2': 0.25740463032738703, 'N': 14759.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student is behind on payments to store (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0038759179342732503, 'coeff_interaction': 0.009133684274612155, 'se_treatment': 0.007522768806404744, 'se_interaction': 0.04118435954046678, 'control_mean': 0.27552703, 'control_sd': 0.4468262195587158, 'f_test_p_value': None, 'r2': 0.18622178408788947, 'N': 10959.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has bought electronics shoes or clothing on installments (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0024291773917717373, 'coeff_interaction': -0.0030837263927155486, 'se_treatment': 0.006835310334958217, 'se_interaction': 0.014742235763410898, 'control_mean': 0.24677002, 'control_sd': 0.4311743378639221, 'f_test_p_value': None, 'r2': 0.2568155171619221, 'N': 14636.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has bought electronics shoes or clothing on installments (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0008049255889684605, 'coeff_interaction': 0.0060464807712722595, 'se_treatment': 0.008919635232615752, 'se_interaction': 0.018241895655085296, 'control_mean': 0.27558333, 'control_sd': 0.44684356451034546, 'f_test_p_value': None, 'r2': 0.18678613935177746, 'N': 10880.0, 'N_clust': 796}\n"
     ]
    }
   ],
   "source": [
    "interaction_var_0 = ['Student is not working at the moment (Baseline)',\n",
    "       'Student works as employee or other (Baseline)',\n",
    "       'Student is behind on payments (unconditional) (Baseline)',\n",
    "       'Student is behind on payments to store (Baseline)',\n",
    "       'Student has bought electronics shoes or clothing on installments (Baseline)']\n",
    "\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "interaction_results = []\n",
    "for interaction_var in interaction_var_0:\n",
    "    data = df\n",
    "    data = data.dropna(subset=['treatment', outcome, 'round', 'cd_escola', interaction_var])\n",
    "    data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
    "    # Create Panel D for interaction analysis\n",
    "    for round_ in [0, 1]:\n",
    "        subset = data[data['round'] == round_].dropna(subset=['treatment', outcome, interaction_var, 'cd_escola'])\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        subset['cd_escola'] = subset['cd_escola'].astype('category')\n",
    "        \n",
    "        bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "        subset[f'miss_{bl}'] = 0\n",
    "        subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "        subset[bl].fillna(0, inplace=True)\n",
    "        \n",
    "        subset['miss_f_coded'] = 0\n",
    "        subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "        subset['female_coded'].fillna(0, inplace=True)\n",
    "        \n",
    "        subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "        pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "        subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "        pair_dummies = pair_dummies.astype('int')\n",
    "        \n",
    "        # Add interaction term\n",
    "        subset['interaction_term'] = subset['treatment'] * subset[interaction_var]\n",
    "\n",
    "        # Panel D regression (with interaction term, clustered standard errors\n",
    "        X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded', \n",
    "                                              interaction_var, 'interaction_term']], pair_dummies], axis=1))\n",
    "        y = subset[outcome]\n",
    "\n",
    "        model_d = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "        # Calculate control group statistics for this panel\n",
    "        control_group = subset[subset['treatment'] == 0]\n",
    "        control_mean = control_group[outcome].mean()\n",
    "        control_sd = control_group[outcome].std()\n",
    "\n",
    "        # Collect results for Panel D\n",
    "        interaction_results.append({\n",
    "            'panel': 'D',\n",
    "            'round': round_,\n",
    "            'interaction varialbe': interaction_var,\n",
    "            'outcome': outcome,\n",
    "            'coeff_treatment': model_d.params['treatment'],\n",
    "            'coeff_interaction': model_d.params['interaction_term'],\n",
    "            'se_treatment': model_d.bse['treatment'],\n",
    "            'se_interaction': model_d.bse['interaction_term'],\n",
    "            'control_mean': control_mean,\n",
    "            'control_sd': control_sd,\n",
    "            'f_test_p_value': None, \n",
    "            'r2': model_d.rsquared,\n",
    "            'N': model_d.nobs,\n",
    "            'N_clust': subset['cd_escola'].nunique()\n",
    "        })\n",
    "\n",
    "   \n",
    " for interaction_results in interaction_results:\n",
    "    print(interaction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6856f79",
   "metadata": {},
   "source": [
    "### Cluster 2 Interaction Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d73f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53/337848369.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_53/337848369.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_53/337848369.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_53/337848369.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel': 'D', 'round': 0, 'interaction varialbe': \"Student's Family receives Bolsa Familia cash transfer (Baseline)\", 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.00121846545543026, 'coeff_interaction': -0.010381619405374545, 'se_treatment': 0.00784942145212125, 'se_interaction': 0.014159759912600831, 'control_mean': 0.25022393, 'control_sd': 0.433175653219223, 'f_test_p_value': None, 'r2': 0.25139388843616006, 'N': 13990.0, 'N_clust': 837}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': \"Student's Family receives Bolsa Familia cash transfer (Baseline)\", 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.007443285810048134, 'coeff_interaction': 0.004320906774172677, 'se_treatment': 0.009816451118732446, 'se_interaction': 0.01719832244321929, 'control_mean': 0.2792584, 'control_sd': 0.44868266582489014, 'f_test_p_value': None, 'r2': 0.18141128180109467, 'N': 10375.0, 'N_clust': 791}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has borrowed money (any source) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0048965546971348065, 'coeff_interaction': 0.007879668376701982, 'se_treatment': 0.006840093021963, 'se_interaction': 0.014086610130176919, 'control_mean': 0.24932288, 'control_sd': 0.43263739347457886, 'f_test_p_value': None, 'r2': 0.2575208582486975, 'N': 14780.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has borrowed money (any source) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.003467793769633744, 'coeff_interaction': 0.0271574633786531, 'se_treatment': 0.009008297989544417, 'se_interaction': 0.018318813471802014, 'control_mean': 0.27597582, 'control_sd': 0.44705232977867126, 'f_test_p_value': None, 'r2': 0.1871599298270441, 'N': 10965.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student is behind on payments to family friends or other people (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0038382465284020053, 'coeff_interaction': 0.013539031869373032, 'se_treatment': 0.00559757853716667, 'se_interaction': 0.026241529283912886, 'control_mean': 0.24889396, 'control_sd': 0.432394415140152, 'f_test_p_value': None, 'r2': 0.256715236491034, 'N': 14759.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student is behind on payments to family friends or other people (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.004560336524206689, 'coeff_interaction': -0.003731928262231579, 'se_treatment': 0.007589563479700458, 'se_interaction': 0.0364727548371623, 'control_mean': 0.27552703, 'control_sd': 0.4468262195587158, 'f_test_p_value': None, 'r2': 0.18597573330256156, 'N': 10959.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Parent occupation is other (homemaker, retired, unemployed, other) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0013710246579763839, 'coeff_interaction': -0.0029056012376731622, 'se_treatment': 0.007743660642125894, 'se_interaction': 0.013257530944021097, 'control_mean': 0.24145229, 'control_sd': 0.4279966652393341, 'f_test_p_value': None, 'r2': 0.2610741667544474, 'N': 12929.0, 'N_clust': 836}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Parent occupation is other (homemaker, retired, unemployed, other) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.005884903197922986, 'coeff_interaction': -0.005017232195734378, 'se_treatment': 0.010273280717381454, 'se_interaction': 0.017487582942605714, 'control_mean': 0.2762994, 'control_sd': 0.4472208619117737, 'f_test_p_value': None, 'r2': 0.19436658373948001, 'N': 9719.0, 'N_clust': 784}\n"
     ]
    }
   ],
   "source": [
    "interaction_var_0 = ['Student\\'s Family receives Bolsa Familia cash transfer (Baseline)',\n",
    "       'Student has borrowed money (any source) (Baseline)',\n",
    "       'Student is behind on payments to family friends or other people (Baseline)',\n",
    "       'Parent occupation is other (homemaker, retired, unemployed, other) (Baseline)']\n",
    "\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "interaction_results = []\n",
    "for interaction_var in interaction_var_0:\n",
    "    data = df\n",
    "    data = data.dropna(subset=['treatment', outcome, 'round', 'cd_escola', interaction_var])\n",
    "    data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
    "    # Create Panel D for interaction analysis\n",
    "    for round_ in [0, 1]:\n",
    "        subset = data[data['round'] == round_].dropna(subset=['treatment', outcome, interaction_var, 'cd_escola'])\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        subset['cd_escola'] = subset['cd_escola'].astype('category')\n",
    "        \n",
    "        bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "        subset[f'miss_{bl}'] = 0\n",
    "        subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "        subset[bl].fillna(0, inplace=True)\n",
    "        \n",
    "        subset['miss_f_coded'] = 0\n",
    "        subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "        subset['female_coded'].fillna(0, inplace=True)\n",
    "        \n",
    "        subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "        pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "        subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "        pair_dummies = pair_dummies.astype('int')\n",
    "        \n",
    "        # Add interaction term\n",
    "        subset['interaction_term'] = subset['treatment'] * subset[interaction_var]\n",
    "\n",
    "        # Panel D regression (with interaction term, clustered standard errors\n",
    "        X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded', \n",
    "                                              interaction_var, 'interaction_term']], pair_dummies], axis=1))\n",
    "        y = subset[outcome]\n",
    "\n",
    "        model_d = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "        # Calculate control group statistics for this panel\n",
    "        control_group = subset[subset['treatment'] == 0]\n",
    "        control_mean = control_group[outcome].mean()\n",
    "        control_sd = control_group[outcome].std()\n",
    "\n",
    "        # Collect results for Panel D\n",
    "        interaction_results.append({\n",
    "            'panel': 'D',\n",
    "            'round': round_,\n",
    "            'interaction varialbe': interaction_var,\n",
    "            'outcome': outcome,\n",
    "            'coeff_treatment': model_d.params['treatment'],\n",
    "            'coeff_interaction': model_d.params['interaction_term'],\n",
    "            'se_treatment': model_d.bse['treatment'],\n",
    "            'se_interaction': model_d.bse['interaction_term'],\n",
    "            'control_mean': control_mean,\n",
    "            'control_sd': control_sd,\n",
    "            'f_test_p_value': None, \n",
    "            'r2': model_d.rsquared,\n",
    "            'N': model_d.nobs,\n",
    "            'N_clust': subset['cd_escola'].nunique()\n",
    "        })\n",
    "\n",
    "# Print or inspect results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"OLS Regression Results with Interaction Term\", dataframe=pd.DataFrame(results))\n",
    "for interaction_results in interaction_results:\n",
    "    print(interaction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8847d0",
   "metadata": {},
   "source": [
    "### Cluster 3 Interaction Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb29498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_133/2086952660.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student is female (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0009443534909191441, 'coeff_interaction': -0.006518116620920198, 'se_treatment': 0.009398917691288772, 'se_interaction': 0.013266810819677633, 'control_mean': 0.24944353, 'control_sd': 0.4327235221862793, 'f_test_p_value': None, 'r2': 0.24950294383474336, 'N': 14084.0, 'N_clust': 837}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student is female (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0010270456276591823, 'coeff_interaction': -0.007233552096475696, 'se_treatment': 0.012569619176013413, 'se_interaction': 0.01747389326464412, 'control_mean': 0.278119, 'control_sd': 0.4481126666069031, 'f_test_p_value': None, 'r2': 0.18048512916991688, 'N': 10450.0, 'N_clust': 791}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has computer with internet at home (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.00922743385404752, 'coeff_interaction': 0.010404930430737504, 'se_treatment': 0.009988129214650926, 'se_interaction': 0.013627403565423527, 'control_mean': 0.24954847, 'control_sd': 0.43277812004089355, 'f_test_p_value': None, 'r2': 0.25495766556144417, 'N': 13888.0, 'N_clust': 837}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has computer with internet at home (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.007836750299676676, 'coeff_interaction': 0.0034171470436215982, 'se_treatment': 0.012988156119043168, 'se_interaction': 0.01803956248383264, 'control_mean': 0.2786215, 'control_sd': 0.44836875796318054, 'f_test_p_value': None, 'r2': 0.18765941068699243, 'N': 10302.0, 'N_clust': 790}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student receives income (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.006888334307035917, 'coeff_interaction': -0.016623398588121705, 'se_treatment': 0.01012209532896204, 'se_interaction': 0.013310629493012245, 'control_mean': 0.24925733, 'control_sd': 0.43261513113975525, 'f_test_p_value': None, 'r2': 0.2574971391717379, 'N': 14878.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student receives income (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.006856502711387944, 'coeff_interaction': -0.006073724896158317, 'se_treatment': 0.012104079247414093, 'se_interaction': 0.0157246049919161, 'control_mean': 0.27660733, 'control_sd': 0.44737350940704346, 'f_test_p_value': None, 'r2': 0.18981874784058939, 'N': 11037.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has bought electronics shoes or clothing with cash/debit card (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0049151436630812, 'coeff_interaction': 0.0025072991339150693, 'se_treatment': 0.015550037883782137, 'se_interaction': 0.017455749377470173, 'control_mean': 0.24798073, 'control_sd': 0.4318888187408447, 'f_test_p_value': None, 'r2': 0.255513071500839, 'N': 14846.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has bought electronics shoes or clothing with cash/debit card (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.018739115969284053, 'coeff_interaction': 0.026634985808602678, 'se_treatment': 0.01892348589330112, 'se_interaction': 0.021688572821778183, 'control_mean': 0.27555475, 'control_sd': 0.4468335509300232, 'f_test_p_value': None, 'r2': 0.18535272948172765, 'N': 11015.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student negotiates prices or payment methods (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.02314865384475329, 'coeff_interaction': 0.024851563168151625, 'se_treatment': 0.012429623968214398, 'se_interaction': 0.015362934990298692, 'control_mean': 0.24877486, 'control_sd': 0.4323331415653229, 'f_test_p_value': None, 'r2': 0.2568536929920222, 'N': 14620.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student negotiates prices or payment methods (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.01927846473160625, 'coeff_interaction': -0.020949476977435787, 'se_treatment': 0.016265467490077793, 'se_interaction': 0.019151937575095413, 'control_mean': 0.2767446, 'control_sd': 0.44743019342422485, 'f_test_p_value': None, 'r2': 0.1861517610156569, 'N': 10892.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student comparison shops before making purchase (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0288490281780419, 'coeff_interaction': 0.0293713977730082, 'se_treatment': 0.025619532373824923, 'se_interaction': 0.026604917503971294, 'control_mean': 0.24797384, 'control_sd': 0.43186643719673157, 'f_test_p_value': None, 'r2': 0.2558955331514329, 'N': 14819.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student comparison shops before making purchase (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.013657008189032446, 'coeff_interaction': 0.018962480655958562, 'se_treatment': 0.02945178915655388, 'se_interaction': 0.030931306756949592, 'control_mean': 0.2763709, 'control_sd': 0.44723567366600037, 'f_test_p_value': None, 'r2': 0.18607859141121574, 'N': 11019.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Parent: has savings account (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.008444137893905164, 'coeff_interaction': 0.016078457516063474, 'se_treatment': 0.008948124937525264, 'se_interaction': 0.013649687250995532, 'control_mean': 0.24086405, 'control_sd': 0.42765262722969055, 'f_test_p_value': None, 'r2': 0.25826828992811635, 'N': 12960.0, 'N_clust': 836}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Parent: has savings account (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.004297067935706859, 'coeff_interaction': -0.009936800645510294, 'se_treatment': 0.011880234316755897, 'se_interaction': 0.017649823858671372, 'control_mean': 0.27115104, 'control_sd': 0.4446110427379608, 'f_test_p_value': None, 'r2': 0.19300167046159178, 'N': 9683.0, 'N_clust': 785}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': ' Parent: has formal savings (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.005717808489668951, 'coeff_interaction': 0.006702930623989786, 'se_treatment': 0.01114791470314567, 'se_interaction': 0.013756481440003935, 'control_mean': 0.2432389, 'control_sd': 0.4290684461593628, 'f_test_p_value': None, 'r2': 0.2589554639145889, 'N': 13100.0, 'N_clust': 836}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': ' Parent: has formal savings (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.013063576615636355, 'coeff_interaction': 0.017300467761391505, 'se_treatment': 0.015056517244892445, 'se_interaction': 0.018357764328579742, 'control_mean': 0.27122837, 'control_sd': 0.44463807344436646, 'f_test_p_value': None, 'r2': 0.19371595792266516, 'N': 9807.0, 'N_clust': 785}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Parent: Student talks to you about finances (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.008137228300414943, 'coeff_interaction': 0.009026965753207468, 'se_treatment': 0.010350592038552719, 'se_interaction': 0.013761025776919449, 'control_mean': 0.24457718, 'control_sd': 0.4298703968524933, 'f_test_p_value': None, 'r2': 0.25735730021991987, 'N': 13381.0, 'N_clust': 837}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Parent: Student talks to you about finances (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0006479364490968526, 'coeff_interaction': -0.0064080642924901725, 'se_treatment': 0.01343808423602256, 'se_interaction': 0.01779044270466189, 'control_mean': 0.2734818, 'control_sd': 0.44578513503074646, 'f_test_p_value': None, 'r2': 0.18966335317214744, 'N': 9990.0, 'N_clust': 785}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Parent: Student helps organize HH budget (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.012054488288845054, 'coeff_interaction': 0.023765153847837363, 'se_treatment': 0.008038805386887029, 'se_interaction': 0.013748463633515064, 'control_mean': 0.24370012, 'control_sd': 0.42935043573379517, 'f_test_p_value': None, 'r2': 0.2590683323656686, 'N': 13426.0, 'N_clust': 837}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Parent: Student helps organize HH budget (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.004574205272203612, 'coeff_interaction': 0.0008652526506606802, 'se_treatment': 0.010381287866849753, 'se_interaction': 0.01670070104833755, 'control_mean': 0.27402493, 'control_sd': 0.4460628926753998, 'f_test_p_value': None, 'r2': 0.19023249419331334, 'N': 10028.0, 'N_clust': 785}\n"
     ]
    }
   ],
   "source": [
    "interaction_var_0 = ['Student is female (Baseline)',\n",
    "       'Student has computer with internet at home (Baseline)',\n",
    "       'Student receives income (Baseline)',\n",
    "       'Student has bought electronics shoes or clothing with cash/debit card (Baseline)',\n",
    "       'Student negotiates prices or payment methods (Baseline)',\n",
    "       'Student comparison shops before making purchase (Baseline)',\n",
    "       'Parent: has savings account (Baseline)',\n",
    "       ' Parent: has formal savings (Baseline)',\n",
    "       'Parent: Student talks to you about finances (Baseline)',\n",
    "       'Parent: Student helps organize HH budget (Baseline)']\n",
    "\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "interaction_results = []\n",
    "for interaction_var in interaction_var_0:\n",
    "    data = df\n",
    "    data = data.dropna(subset=['treatment', outcome, 'round', 'cd_escola', interaction_var])\n",
    "    data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
    "    # Create Panel D for interaction analysis\n",
    "    for round_ in [0, 1]:\n",
    "        subset = data[data['round'] == round_].dropna(subset=['treatment', outcome, interaction_var, 'cd_escola'])\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        subset['cd_escola'] = subset['cd_escola'].astype('category')\n",
    "        \n",
    "        bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "        subset[f'miss_{bl}'] = 0\n",
    "        subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "        subset[bl].fillna(0, inplace=True)\n",
    "        \n",
    "        subset['miss_f_coded'] = 0\n",
    "        subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "        subset['female_coded'].fillna(0, inplace=True)\n",
    "        \n",
    "        subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "        pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "        subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "        pair_dummies = pair_dummies.astype('int')\n",
    "        \n",
    "        # Add interaction term\n",
    "        subset['interaction_term'] = subset['treatment'] * subset[interaction_var]\n",
    "\n",
    "        # Panel D regression (with interaction term, clustered standard errors\n",
    "        X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded', \n",
    "                                              interaction_var, 'interaction_term']], pair_dummies], axis=1))\n",
    "        y = subset[outcome]\n",
    "\n",
    "        model_d = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "        # Calculate control group statistics for this panel\n",
    "        control_group = subset[subset['treatment'] == 0]\n",
    "        control_mean = control_group[outcome].mean()\n",
    "        control_sd = control_group[outcome].std()\n",
    "\n",
    "        # Collect results for Panel D\n",
    "        interaction_results.append({\n",
    "            'panel': 'D',\n",
    "            'round': round_,\n",
    "            'interaction varialbe': interaction_var,\n",
    "            'outcome': outcome,\n",
    "            'coeff_treatment': model_d.params['treatment'],\n",
    "            'coeff_interaction': model_d.params['interaction_term'],\n",
    "            'se_treatment': model_d.bse['treatment'],\n",
    "            'se_interaction': model_d.bse['interaction_term'],\n",
    "            'control_mean': control_mean,\n",
    "            'control_sd': control_sd,\n",
    "            'f_test_p_value': None, \n",
    "            'r2': model_d.rsquared,\n",
    "            'N': model_d.nobs,\n",
    "            'N_clust': subset['cd_escola'].nunique()\n",
    "        })\n",
    "\n",
    "# Print or inspect results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"OLS Regression Results with Interaction Term\", dataframe=pd.DataFrame(results))\n",
    "for interaction_results in interaction_results:\n",
    "    print(interaction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b821cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Student has computer with internet at home (Baseline)',\n",
    "'Student says they are a saver (Baseline)',\n",
    "'Student receives income (Baseline)',\n",
    "'Student has borrowed money (any source) (Baseline)',\n",
    "'Student has bought electronics, shoes, or clothing with cash/debit card (Baseline)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f88adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_175/3560229258.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_175/3560229258.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_175/3560229258.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_175/3560229258.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
      "/tmp/ipykernel_175/3560229258.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has computer with internet at home (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.00922743385404752, 'coeff_interaction': 0.010404930430737504, 'se_treatment': 0.009988129214650926, 'se_interaction': 0.013627403565423527, 'p_value_treatment': 0.35556959656534215, 'p_value_interaction': 0.4451474222801831, 'control_mean': 0.24954847, 'control_sd': 0.43277812004089355, 'f_test_p_value': None, 'r2': 0.25495766556144417, 'N': 13888.0, 'N_clust': 837}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has computer with internet at home (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.007836750299676676, 'coeff_interaction': 0.0034171470436215982, 'se_treatment': 0.012988156119043168, 'se_interaction': 0.01803956248383264, 'p_value_treatment': 0.5462581433788041, 'p_value_interaction': 0.8497596051264917, 'control_mean': 0.2786215, 'control_sd': 0.44836875796318054, 'f_test_p_value': None, 'r2': 0.18765941068699243, 'N': 10302.0, 'N_clust': 790}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student says they are a saver (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.005802560136175293, 'coeff_interaction': 0.009482251316173577, 'se_treatment': 0.0070792429797288964, 'se_interaction': 0.013128692409689386, 'p_value_treatment': 0.41241093876932833, 'p_value_interaction': 0.47013829557903386, 'control_mean': 0.2491794, 'control_sd': 0.4325709044933319, 'f_test_p_value': None, 'r2': 0.2583737721850039, 'N': 14749.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student says they are a saver (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.0033554510668432165, 'coeff_interaction': 0.006541953619539841, 'se_treatment': 0.00949567291661457, 'se_interaction': 0.017235945758054462, 'p_value_treatment': 0.7238138262418354, 'p_value_interaction': 0.7042773109213165, 'control_mean': 0.2757798, 'control_sd': 0.44694268703460693, 'f_test_p_value': None, 'r2': 0.18971967835827508, 'N': 10942.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student receives income (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.006888334307035917, 'coeff_interaction': -0.016623398588121705, 'se_treatment': 0.01012209532896204, 'se_interaction': 0.013310629493012245, 'p_value_treatment': 0.49617238639379413, 'p_value_interaction': 0.21170842833084624, 'control_mean': 0.24925733, 'control_sd': 0.43261513113975525, 'f_test_p_value': None, 'r2': 0.2574971391717379, 'N': 14878.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student receives income (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': 0.006856502711387944, 'coeff_interaction': -0.006073724896158317, 'se_treatment': 0.012104079247414093, 'se_interaction': 0.0157246049919161, 'p_value_treatment': 0.5710796584442575, 'p_value_interaction': 0.6993069954932969, 'control_mean': 0.27660733, 'control_sd': 0.44737350940704346, 'f_test_p_value': None, 'r2': 0.18981874784058939, 'N': 11037.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has borrowed money (any source) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0048965546971348065, 'coeff_interaction': 0.007879668376701982, 'se_treatment': 0.006840093021963, 'se_interaction': 0.014086610130176919, 'p_value_treatment': 0.47407728433084906, 'p_value_interaction': 0.5759072322133392, 'control_mean': 0.24932288, 'control_sd': 0.43263739347457886, 'f_test_p_value': None, 'r2': 0.2575208582486975, 'N': 14780.0, 'N_clust': 839}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has borrowed money (any source) (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.003467793769633744, 'coeff_interaction': 0.0271574633786531, 'se_treatment': 0.009008297989544417, 'se_interaction': 0.018318813471802014, 'p_value_treatment': 0.7002703925556366, 'p_value_interaction': 0.1382098812509473, 'control_mean': 0.27597582, 'control_sd': 0.44705232977867126, 'f_test_p_value': None, 'r2': 0.1871599298270441, 'N': 10965.0, 'N_clust': 796}\n",
      "{'panel': 'D', 'round': 0, 'interaction varialbe': 'Student has bought electronics shoes or clothing with cash/debit card (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.0049151436630812, 'coeff_interaction': 0.0025072991339150693, 'se_treatment': 0.015550037883782137, 'se_interaction': 0.017455749377470173, 'p_value_treatment': 0.7519375066892346, 'p_value_interaction': 0.8857867752615637, 'control_mean': 0.24798073, 'control_sd': 0.4318888187408447, 'f_test_p_value': None, 'r2': 0.255513071500839, 'N': 14846.0, 'N_clust': 840}\n",
      "{'panel': 'D', 'round': 1, 'interaction varialbe': 'Student has bought electronics shoes or clothing with cash/debit card (Baseline)', 'outcome': 'I have bought electronics shoes or clothing with credit card', 'coeff_treatment': -0.018739115969284053, 'coeff_interaction': 0.026634985808602678, 'se_treatment': 0.01892348589330112, 'se_interaction': 0.021688572821778183, 'p_value_treatment': 0.32204847707000905, 'p_value_interaction': 0.2194224191512283, 'control_mean': 0.27555475, 'control_sd': 0.4468335509300232, 'f_test_p_value': None, 'r2': 0.18535272948172765, 'N': 11015.0, 'N_clust': 796}\n"
     ]
    }
   ],
   "source": [
    "interaction_var_0 = ['Student has computer with internet at home (Baseline)',\n",
    "'Student says they are a saver (Baseline)',\n",
    "'Student receives income (Baseline)',\n",
    "'Student has borrowed money (any source) (Baseline)',\n",
    "'Student has bought electronics shoes or clothing with cash/debit card (Baseline)']\n",
    "\n",
    "outcome = 'I have bought electronics shoes or clothing with credit card'\n",
    "interaction_results = []\n",
    "for interaction_var in interaction_var_0:\n",
    "    data = df\n",
    "    data = data.dropna(subset=['treatment', outcome, 'round', 'cd_escola', interaction_var])\n",
    "    data.loc[:, 'interaction_term'] = data['treatment'] * data[interaction_var]\n",
    "    # Create Panel D for interaction analysis\n",
    "    for round_ in [0, 1]:\n",
    "        subset = data[data['round'] == round_].dropna(subset=['treatment', outcome, interaction_var, 'cd_escola'])\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        subset['cd_escola'] = subset['cd_escola'].astype('category')\n",
    "        \n",
    "        bl = 'Student has bought electronics shoes or clothing with credit card (Baseline)'\n",
    "        subset[f'miss_{bl}'] = 0\n",
    "        subset.loc[subset[bl].isnull(), f'miss_{bl}'] = 1\n",
    "        subset[bl].fillna(0, inplace=True)\n",
    "        \n",
    "        subset['miss_f_coded'] = 0\n",
    "        subset.loc[subset['female_coded'].isnull(), 'miss_f_coded'] = 1\n",
    "        subset['female_coded'].fillna(0, inplace=True)\n",
    "        \n",
    "        subset[f'pair_{outcome}{round_}'] = subset['pair_all']\n",
    "        pair_dummies = pd.get_dummies(subset[f'pair_{outcome}{round_}'], prefix=f'pair_{round_}', drop_first=True)\n",
    "        subset = pd.concat([subset, pair_dummies], axis=1)\n",
    "        pair_dummies = pair_dummies.astype('int')\n",
    "        \n",
    "        # Add interaction term\n",
    "        subset['interaction_term'] = subset['treatment'] * subset[interaction_var]\n",
    "\n",
    "        # Panel D regression (with interaction term, clustered standard errors\n",
    "        X = sm.add_constant(pd.concat([subset[['treatment', bl, f'miss_{bl}', \n",
    "                                           'female_coded', 'miss_f_coded', \n",
    "                                              interaction_var, 'interaction_term']], pair_dummies], axis=1))\n",
    "        y = subset[outcome]\n",
    "\n",
    "        model_d = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': subset['cd_escola']})\n",
    "\n",
    "        # Calculate control group statistics for this panel\n",
    "        control_group = subset[subset['treatment'] == 0]\n",
    "        control_mean = control_group[outcome].mean()\n",
    "        control_sd = control_group[outcome].std()\n",
    "        \n",
    "        # Perform an F-test for joint significance of 'treatment' and 'interaction_term'\n",
    "        f_test = model_d.f_test(\"treatment = 0, interaction_term = 0\")\n",
    "        p_value_f_test = f_test.pvalue\n",
    "\n",
    "        f_test = model_d.f_test(\"treatment = 0, interaction_term = 0\")\n",
    "        p_value_f_test = f_test.pvalue\n",
    "\n",
    "        # Collect results for Panel D\n",
    "        interaction_results.append({\n",
    "        'panel': 'D',\n",
    "        'round': round_,\n",
    "        'interaction varialbe': interaction_var,\n",
    "        'outcome': outcome,\n",
    "        'coeff_treatment': model_d.params['treatment'],\n",
    "        'coeff_interaction': model_d.params['interaction_term'],\n",
    "        'se_treatment': model_d.bse['treatment'],\n",
    "        'se_interaction': model_d.bse['interaction_term'],\n",
    "        'p_value_treatment': model_d.pvalues['treatment'],  # Add p-value for treatment\n",
    "        'p_value_interaction': model_d.pvalues['interaction_term'],  # Add p-value for interaction term\n",
    "        'control_mean': control_mean,\n",
    "        'control_sd': control_sd,\n",
    "        'f_test_p_value': None, \n",
    "        'r2': model_d.rsquared,\n",
    "        'N': model_d.nobs,\n",
    "        'N_clust': subset['cd_escola'].nunique()\n",
    "        })\n",
    "\n",
    "# Print or inspect results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"OLS Regression Results with Interaction Term\", dataframe=pd.DataFrame(results))\n",
    "for interaction_results in interaction_results:\n",
    "    print(interaction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab672ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
